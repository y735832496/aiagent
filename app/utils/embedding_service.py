import numpy as np
from typing import List, Union
from sentence_transformers import SentenceTransformer
from app.config import settings

class EmbeddingService:
    """å‘é‡åŒ–æœåŠ¡"""
    
    def __init__(self, model_name: str = None):
        self.model_name = model_name or settings.embedding_model
        self.model = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½å‘é‡åŒ–æ¨¡å‹"""
        try:
            print(f"æ­£åœ¨åŠ è½½å‘é‡åŒ–æ¨¡å‹: {self.model_name}")
            self.model = SentenceTransformer(self.model_name)
            print(f"âœ… æˆåŠŸåŠ è½½å‘é‡åŒ–æ¨¡å‹: {self.model_name}")
            # è‡ªåŠ¨æ‰“å°å®é™…æ¨¡å‹åå’Œç»´åº¦
            print(f"[DEBUG] å®é™…åŠ è½½æ¨¡å‹: {getattr(self.model, 'name_or_path', 'unknown')}, ç»´åº¦: {self.model.get_sentence_embedding_dimension()}")
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹ {self.model_name} å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹ä½œä¸ºå¤‡é€‰
            try:
                print("ğŸ”„ å°è¯•åŠ è½½å¤‡é€‰æ¨¡å‹: all-MiniLM-L6-v2")
                self.model = SentenceTransformer('all-MiniLM-L6-v2')
                self.model_name = 'all-MiniLM-L6-v2'
                print("âœ… æˆåŠŸåŠ è½½å¤‡é€‰æ¨¡å‹")
            except Exception as e2:
                print(f"âŒ å¤‡é€‰æ¨¡å‹ä¹ŸåŠ è½½å¤±è´¥: {e2}")
                raise RuntimeError(f"æ— æ³•åŠ è½½ä»»ä½•å‘é‡åŒ–æ¨¡å‹: {e2}")
    
    def encode_text(self, text: Union[str, List[str]]) -> Union[List[float], List[List[float]]]:
        """ç¼–ç æ–‡æœ¬ä¸ºå‘é‡"""
        if not self.model:
            raise RuntimeError("å‘é‡åŒ–æ¨¡å‹æœªåŠ è½½")
        
        try:
            embeddings = self.model.encode(text, convert_to_numpy=True)
            
            # å¦‚æœæ˜¯å•ä¸ªæ–‡æœ¬ï¼Œè¿”å›ä¸€ç»´åˆ—è¡¨
            if isinstance(text, str):
                return embeddings.tolist()
            else:
                return embeddings.tolist()
                
        except Exception as e:
            print(f"å‘é‡åŒ–å¤±è´¥: {e}")
            raise
    
    def encode_single_text(self, text: str) -> List[float]:
        """ç¼–ç å•ä¸ªæ–‡æœ¬"""
        return self.encode_text(text)
    
    def get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤ºï¼ˆencode_single_textçš„åˆ«åï¼‰"""
        return self.encode_single_text(text)
    
    def encode_batch_texts(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡ç¼–ç æ–‡æœ¬"""
        return self.encode_text(texts)
    
    def compute_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        similarity = dot_product / (norm1 * norm2)
        return float(similarity)
    
    def find_most_similar(self, query_vector: List[float], candidate_vectors: List[List[float]], top_k: int = 5) -> List[tuple]:
        """æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å‘é‡"""
        similarities = []
        
        for i, candidate in enumerate(candidate_vectors):
            similarity = self.compute_similarity(query_vector, candidate)
            similarities.append((i, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        return similarities[:top_k]
    
    def get_model_info(self) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        if not self.model:
            return {"status": "not_loaded"}
        
        return {
            "model_name": self.model_name,
            "max_seq_length": getattr(self.model, 'max_seq_length', 'unknown'),
            "embedding_dimension": self.model.get_sentence_embedding_dimension(),
            "status": "loaded"
        } 