#!/usr/bin/env python3
"""
åˆ†æainvokeçš„å…·ä½“å®ç°è¿‡ç¨‹
"""

import os
import sys
import asyncio
import time
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.config import settings
from app.services.langchain_service import LangChainRAGService


async def analyze_ainvoke_process():
    """åˆ†æainvokeçš„å®Œæ•´å®ç°è¿‡ç¨‹"""
    print("ğŸ” åˆ†æainvokeçš„å…·ä½“å®ç°è¿‡ç¨‹")
    print("=" * 60)
    
    # åˆå§‹åŒ–æœåŠ¡
    print("ğŸš€ åˆå§‹åŒ–LangChainæœåŠ¡...")
    langchain_service = LangChainRAGService()
    
    if not langchain_service.vector_store:
        print("âŒ å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–")
        return
    
    # æµ‹è¯•æŸ¥è¯¢
    test_query = "ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“ï¼Ÿ"
    print(f"\nğŸ“ æµ‹è¯•æŸ¥è¯¢: '{test_query}'")
    
    # è¯¦ç»†åˆ†æainvokeçš„æ‰§è¡Œè¿‡ç¨‹
    print("\nğŸ”„ ainvokeæ‰§è¡Œè¿‡ç¨‹åˆ†æ:")
    print("=" * 40)
    
    # 1. åˆ›å»ºæ£€ç´¢å™¨
    print("1ï¸âƒ£ åˆ›å»ºæ£€ç´¢å™¨...")
    retriever = langchain_service.vector_store.as_retriever(
        search_type="similarity",
        search_kwargs={
            "k": 5,
            "score_threshold": 0.3
        }
    )
    print("   âœ… æ£€ç´¢å™¨åˆ›å»ºå®Œæˆ")
    
    # 2. åˆ›å»ºQAé“¾
    print("\n2ï¸âƒ£ åˆ›å»ºQAé“¾...")
    qa_chain = langchain_service.chain_type(
        llm=langchain_service.llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={
            "prompt": langchain_service._get_qa_prompt()
        }
    )
    print("   âœ… QAé“¾åˆ›å»ºå®Œæˆ")
    
    # 3. æ‰§è¡Œainvoke
    print("\n3ï¸âƒ£ æ‰§è¡Œainvoke...")
    start_time = time.time()
    
    try:
        # è¿™é‡Œæ¨¡æ‹Ÿainvokeçš„å†…éƒ¨æ‰§è¡Œè¿‡ç¨‹
        result = await simulate_ainvoke_process(
            qa_chain, 
            test_query, 
            langchain_service
        )
        
        end_time = time.time()
        print(f"   âœ… ainvokeæ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {(end_time - start_time) * 1000:.2f} æ¯«ç§’")
        
        # 4. åˆ†æç»“æœ
        print("\n4ï¸âƒ£ ç»“æœåˆ†æ:")
        print(f"   - ç­”æ¡ˆ: {result.get('result', '')[:100]}...")
        print(f"   - æ¥æºæ–‡æ¡£æ•°: {len(result.get('source_documents', []))}")
        
        # æ˜¾ç¤ºæ¥æºæ–‡æ¡£
        source_docs = result.get('source_documents', [])
        for i, doc in enumerate(source_docs):
            print(f"   - æ¥æº {i+1}: {doc.page_content[:50]}...")
            print(f"     å…ƒæ•°æ®: {doc.metadata}")
        
    except Exception as e:
        print(f"   âŒ ainvokeæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def simulate_ainvoke_process(qa_chain, query: str, langchain_service):
    """æ¨¡æ‹Ÿainvokeçš„å†…éƒ¨æ‰§è¡Œè¿‡ç¨‹"""
    print("   ğŸ” æ¨¡æ‹Ÿainvokeå†…éƒ¨æ‰§è¡Œè¿‡ç¨‹:")
    
    # æ­¥éª¤1: æ£€ç´¢ç›¸å…³æ–‡æ¡£
    print("   ğŸ“„ æ­¥éª¤1: æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
    retriever = qa_chain.retriever
    source_documents = await retriever.aget_relevant_documents(query)
    print(f"      - æ£€ç´¢åˆ° {len(source_documents)} ä¸ªç›¸å…³æ–‡æ¡£")
    
    # æ­¥éª¤2: æ„å»ºä¸Šä¸‹æ–‡
    print("   ğŸ“ æ­¥éª¤2: æ„å»ºä¸Šä¸‹æ–‡...")
    context = ""
    if source_documents:
        # ä½¿ç”¨stuffæ–¹æ³•ï¼šå°†æ‰€æœ‰æ–‡æ¡£å†…å®¹æ‹¼æ¥
        context_parts = [doc.page_content for doc in source_documents]
        context = "\n\n".join(context_parts)
        print(f"      - ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
    
    # æ­¥éª¤3: æ„å»ºæç¤ºè¯
    print("   ğŸ¯ æ­¥éª¤3: æ„å»ºæç¤ºè¯...")
    prompt_template = qa_chain.combine_documents_chain.prompt
    formatted_prompt = prompt_template.format(
        context=context,
        question=query
    )
    print(f"      - æç¤ºè¯é•¿åº¦: {len(formatted_prompt)} å­—ç¬¦")
    
    # æ­¥éª¤4: è°ƒç”¨LLM
    print("   ğŸ¤– æ­¥éª¤4: è°ƒç”¨LLM...")
    llm_response = await langchain_service.llm._acall(
        formatted_prompt,
        max_tokens=1000
    )
    print(f"      - LLMå“åº”é•¿åº¦: {len(llm_response)} å­—ç¬¦")
    
    # æ­¥éª¤5: æ„å»ºæœ€ç»ˆç»“æœ
    print("   ğŸ“Š æ­¥éª¤5: æ„å»ºæœ€ç»ˆç»“æœ...")
    result = {
        "result": llm_response,
        "source_documents": source_documents
    }
    
    return result


def analyze_chain_types():
    """åˆ†æä¸åŒçš„chain_type"""
    print("\nğŸ“š åˆ†æä¸åŒçš„chain_type:")
    print("=" * 40)
    
    chain_types = {
        "stuff": {
            "description": "å°†æ‰€æœ‰æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹ç›´æ¥æ‹¼æ¥",
            "ä¼˜ç‚¹": "ç®€å•ç›´æ¥ï¼Œä¿ç•™æ‰€æœ‰ä¿¡æ¯",
            "ç¼ºç‚¹": "å¯èƒ½è¶…å‡ºLLMçš„ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶",
            "é€‚ç”¨åœºæ™¯": "æ–‡æ¡£æ•°é‡å°‘ï¼Œå†…å®¹ç®€çŸ­"
        },
        "map_reduce": {
            "description": "å…ˆå¯¹æ¯ä¸ªæ–‡æ¡£å•ç‹¬å¤„ç†ï¼Œå†åˆå¹¶ç»“æœ",
            "ä¼˜ç‚¹": "å¯ä»¥å¤„ç†å¤§é‡æ–‡æ¡£ï¼Œå¹¶è¡Œå¤„ç†",
            "ç¼ºç‚¹": "å¯èƒ½ä¸¢å¤±æ–‡æ¡£é—´çš„å…³è”ä¿¡æ¯",
            "é€‚ç”¨åœºæ™¯": "æ–‡æ¡£æ•°é‡å¤šï¼Œéœ€è¦å¹¶è¡Œå¤„ç†"
        },
        "refine": {
            "description": "è¿­ä»£å¼å¤„ç†ï¼Œé€æ­¥å®Œå–„ç­”æ¡ˆ",
            "ä¼˜ç‚¹": "ç­”æ¡ˆè´¨é‡é«˜ï¼Œå¯ä»¥å¤„ç†å¤æ‚é—®é¢˜",
            "ç¼ºç‚¹": "å¤„ç†æ—¶é—´é•¿ï¼Œæˆæœ¬é«˜",
            "é€‚ç”¨åœºæ™¯": "éœ€è¦é«˜è´¨é‡ç­”æ¡ˆçš„å¤æ‚æŸ¥è¯¢"
        }
    }
    
    for chain_type, info in chain_types.items():
        print(f"\nğŸ”— {chain_type.upper()}:")
        print(f"   - æè¿°: {info['description']}")
        print(f"   - ä¼˜ç‚¹: {info['ä¼˜ç‚¹']}")
        print(f"   - ç¼ºç‚¹: {info['ç¼ºç‚¹']}")
        print(f"   - é€‚ç”¨åœºæ™¯: {info['é€‚ç”¨åœºæ™¯']}")


def analyze_retriever_methods():
    """åˆ†ææ£€ç´¢å™¨çš„æ–¹æ³•"""
    print("\nğŸ” åˆ†ææ£€ç´¢å™¨çš„æ–¹æ³•:")
    print("=" * 40)
    
    methods = {
        "aget_relevant_documents": {
            "description": "å¼‚æ­¥è·å–ç›¸å…³æ–‡æ¡£",
            "å‚æ•°": "query: str",
            "è¿”å›": "List[Document]",
            "ç”¨é€”": "åœ¨ainvokeä¸­ç”¨äºæ£€ç´¢ç›¸å…³æ–‡æ¡£"
        },
        "get_relevant_documents": {
            "description": "åŒæ­¥è·å–ç›¸å…³æ–‡æ¡£",
            "å‚æ•°": "query: str", 
            "è¿”å›": "List[Document]",
            "ç”¨é€”": "åœ¨invokeä¸­ç”¨äºæ£€ç´¢ç›¸å…³æ–‡æ¡£"
        },
        "aget_relevant_documents_with_score": {
            "description": "å¼‚æ­¥è·å–ç›¸å…³æ–‡æ¡£åŠç›¸ä¼¼åº¦åˆ†æ•°",
            "å‚æ•°": "query: str",
            "è¿”å›": "List[Tuple[Document, float]]",
            "ç”¨é€”": "éœ€è¦ç›¸ä¼¼åº¦åˆ†æ•°æ—¶ä½¿ç”¨"
        }
    }
    
    for method, info in methods.items():
        print(f"\nğŸ“‹ {method}:")
        print(f"   - æè¿°: {info['description']}")
        print(f"   - å‚æ•°: {info['å‚æ•°']}")
        print(f"   - è¿”å›: {info['è¿”å›']}")
        print(f"   - ç”¨é€”: {info['ç”¨é€”']}")


async def test_actual_ainvoke():
    """æµ‹è¯•å®é™…çš„ainvokeè°ƒç”¨"""
    print("\nğŸ§ª æµ‹è¯•å®é™…çš„ainvokeè°ƒç”¨:")
    print("=" * 40)
    
    langchain_service = LangChainRAGService()
    
    if not langchain_service.vector_store:
        print("âŒ å‘é‡å­˜å‚¨æœªåˆå§‹åŒ–")
        return
    
    test_query = "å‘é‡æ•°æ®åº“æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ"
    print(f"ğŸ“ æµ‹è¯•æŸ¥è¯¢: '{test_query}'")
    
    try:
        # åˆ›å»ºæ£€ç´¢å™¨
        retriever = langchain_service.vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={
                "k": 3,
                "score_threshold": 0.3
            }
        )
        
        # åˆ›å»ºQAé“¾
        qa_chain = langchain_service.chain_type(
            llm=langchain_service.llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={
                "prompt": langchain_service._get_qa_prompt()
            }
        )
        
        # æ‰§è¡Œainvoke
        start_time = time.time()
        print(f"test_query is :{test_query}")
        result = await qa_chain.ainvoke({"query": test_query})
        end_time = time.time()
        
        print(f"âœ… ainvokeæ‰§è¡ŒæˆåŠŸï¼Œè€—æ—¶: {(end_time - start_time) * 1000:.2f} æ¯«ç§’")
        print(f"ğŸ“„ ç­”æ¡ˆ: {result.get('result', '')[:200]}...")
        print(f"ğŸ“š æ¥æºæ–‡æ¡£æ•°: {len(result.get('source_documents', []))}")
        
    except Exception as e:
        print(f"âŒ ainvokeæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    try:
        asyncio.run(analyze_ainvoke_process())
        analyze_chain_types()
        analyze_retriever_methods()
        asyncio.run(test_actual_ainvoke())
        print("\nâœ… åˆ†æå®Œæˆ")
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc() 