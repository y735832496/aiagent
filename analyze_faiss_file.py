#!/usr/bin/env python3
"""
åˆ†æFAISSæ–‡ä»¶çš„å†…å®¹å’Œç»“æ„
"""

import os
import sys
import faiss
import pickle
import numpy as np
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.config import settings


def analyze_faiss_files():
    """åˆ†æFAISSæ–‡ä»¶çš„å†…å®¹"""
    print("ğŸ” åˆ†æFAISSæ–‡ä»¶å†…å®¹")
    print("=" * 50)
    
    vector_store_path = f"{settings.data_dir}/faiss/langchain_vectorstore"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    index_faiss_path = f"{vector_store_path}/index.faiss"
    index_pkl_path = f"{vector_store_path}/index.pkl"
    
    print(f"ğŸ“ å‘é‡å­˜å‚¨è·¯å¾„: {vector_store_path}")
    print(f"ğŸ“„ index.faiss æ–‡ä»¶: {'âœ… å­˜åœ¨' if os.path.exists(index_faiss_path) else 'âŒ ä¸å­˜åœ¨'}")
    print(f"ğŸ“„ index.pkl æ–‡ä»¶: {'âœ… å­˜åœ¨' if os.path.exists(index_pkl_path) else 'âŒ ä¸å­˜åœ¨'}")
    
    if not os.path.exists(index_faiss_path):
        print("âŒ index.faiss æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    # åˆ†æ index.faiss æ–‡ä»¶
    print(f"\nğŸ“Š index.faiss æ–‡ä»¶åˆ†æ:")
    print(f"   - æ–‡ä»¶å¤§å°: {os.path.getsize(index_faiss_path) / 1024:.2f} KB")
    
    try:
        # ç›´æ¥è¯»å–FAISSç´¢å¼•
        index = faiss.read_index(index_faiss_path)
        print(f"   - ç´¢å¼•ç±»å‹: {type(index).__name__}")
        print(f"   - å‘é‡ç»´åº¦: {index.d}")
        print(f"   - å‘é‡æ•°é‡: {index.ntotal}")
        print(f"   - æ˜¯å¦å·²è®­ç»ƒ: {index.is_trained}")
        
        # è®¡ç®—å®é™…å­˜å‚¨çš„å‘é‡æ•°æ®å¤§å°
        actual_vector_size = index.ntotal * index.d * 4  # float32 = 4å­—èŠ‚
        print(f"   - å‘é‡æ•°æ®å¤§å°: {actual_vector_size / 1024:.2f} KB")
        
        # è·å–ä¸€äº›å‘é‡æ ·æœ¬
        if index.ntotal > 0:
            vectors = index.reconstruct_n(0, min(3, index.ntotal))
            print(f"   - å‰{min(3, index.ntotal)}ä¸ªå‘é‡çš„å½¢çŠ¶: {vectors.shape}")
            print(f"   - å‘é‡æ•°æ®ç±»å‹: {vectors.dtype}")
            
            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªå‘é‡çš„å‰10ä¸ªå€¼
            if vectors.size > 0:
                first_vector = vectors[0]
                print(f"   - ç¬¬ä¸€ä¸ªå‘é‡å‰10ä¸ªå€¼: {first_vector[:10]}")
        
    except Exception as e:
        print(f"   - è¯»å–FAISSç´¢å¼•å¤±è´¥: {e}")
    
    # åˆ†æ index.pkl æ–‡ä»¶
    if os.path.exists(index_pkl_path):
        print(f"\nğŸ“Š index.pkl æ–‡ä»¶åˆ†æ:")
        print(f"   - æ–‡ä»¶å¤§å°: {os.path.getsize(index_pkl_path) / 1024:.2f} KB")
        
        try:
            with open(index_pkl_path, 'rb') as f:
                pkl_data = pickle.load(f)
            
            print(f"   - æ•°æ®ç±»å‹: {type(pkl_data)}")
            
            if isinstance(pkl_data, dict):
                print(f"   - å­—å…¸é”®: {list(pkl_data.keys())}")
                
                # åˆ†ææ–‡æ¡£å­˜å‚¨
                if 'docstore' in pkl_data:
                    docstore = pkl_data['docstore']
                    print(f"   - æ–‡æ¡£å­˜å‚¨ç±»å‹: {type(docstore)}")
                    
                    if hasattr(docstore, '_dict'):
                        doc_count = len(docstore._dict)
                        print(f"   - æ–‡æ¡£æ•°é‡: {doc_count}")
                        
                        # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡æ¡£çš„ä¿¡æ¯
                        for i, (doc_id, doc) in enumerate(list(docstore._dict.items())[:3]):
                            print(f"     - æ–‡æ¡£ {i+1}: ID={doc_id}")
                            if hasattr(doc, 'page_content'):
                                content_preview = doc.page_content[:50] + "..." if len(doc.page_content) > 50 else doc.page_content
                                print(f"       å†…å®¹é¢„è§ˆ: {content_preview}")
                            if hasattr(doc, 'metadata'):
                                print(f"       å…ƒæ•°æ®: {doc.metadata}")
                
                # åˆ†æç´¢å¼•æ˜ å°„
                if 'index_to_docstore_id' in pkl_data:
                    mapping = pkl_data['index_to_docstore_id']
                    print(f"   - ç´¢å¼•æ˜ å°„ç±»å‹: {type(mapping)}")
                    print(f"   - æ˜ å°„æ•°é‡: {len(mapping)}")
                    print(f"   - æ˜ å°„ç¤ºä¾‹: {dict(list(mapping.items())[:3])}")
            
        except Exception as e:
            print(f"   - è¯»å–PKLæ–‡ä»¶å¤±è´¥: {e}")
    
    print(f"\nğŸ’¡ FAISSæ–‡ä»¶è¯´æ˜:")
    print(f"   - index.faiss: å­˜å‚¨å‘é‡ç´¢å¼•æ•°æ®ï¼ˆäºŒè¿›åˆ¶æ ¼å¼ï¼‰")
    print(f"   - index.pkl: å­˜å‚¨æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®ï¼ˆPythonåºåˆ—åŒ–æ ¼å¼ï¼‰")
    print(f"   - ä¸¤ä¸ªæ–‡ä»¶é…åˆä½¿ç”¨ï¼Œå®ç°å®Œæ•´çš„å‘é‡å­˜å‚¨")


def compare_memory_vs_disk():
    """æ¯”è¾ƒå†…å­˜å’Œç£ç›˜ä¸­çš„æ•°æ®"""
    print(f"\nğŸ”„ æ¯”è¾ƒå†…å­˜å’Œç£ç›˜ä¸­çš„æ•°æ®")
    print("=" * 50)
    
    # å¯¼å…¥LangChainæœåŠ¡
    from app.services.langchain_service import LangChainRAGService
    
    # åˆå§‹åŒ–æœåŠ¡ï¼ˆä»ç£ç›˜åŠ è½½ï¼‰
    print("ğŸš€ ä»ç£ç›˜åŠ è½½FAISSæ•°æ®åˆ°å†…å­˜...")
    langchain_service = LangChainRAGService()
    
    if langchain_service.vector_store:
        # å†…å­˜ä¸­çš„æ•°æ®
        memory_index = langchain_service.vector_store.index
        memory_docstore = langchain_service.vector_store.docstore
        
        print(f"ğŸ“Š å†…å­˜ä¸­çš„æ•°æ®:")
        print(f"   - å‘é‡æ•°é‡: {memory_index.ntotal}")
        print(f"   - å‘é‡ç»´åº¦: {memory_index.d}")
        print(f"   - æ–‡æ¡£æ•°é‡: {len(memory_docstore._dict) if hasattr(memory_docstore, '_dict') else 'N/A'}")
        
        # ç£ç›˜ä¸­çš„æ•°æ®
        vector_store_path = f"{settings.data_dir}/faiss/langchain_vectorstore"
        disk_index = faiss.read_index(f"{vector_store_path}/index.faiss")
        
        print(f"ğŸ“Š ç£ç›˜ä¸­çš„æ•°æ®:")
        print(f"   - å‘é‡æ•°é‡: {disk_index.ntotal}")
        print(f"   - å‘é‡ç»´åº¦: {disk_index.d}")
        
        # æ¯”è¾ƒ
        print(f"ğŸ“Š æ¯”è¾ƒç»“æœ:")
        print(f"   - å‘é‡æ•°é‡ä¸€è‡´: {'âœ…' if memory_index.ntotal == disk_index.ntotal else 'âŒ'}")
        print(f"   - å‘é‡ç»´åº¦ä¸€è‡´: {'âœ…' if memory_index.d == disk_index.d else 'âŒ'}")
        
        # éªŒè¯å‘é‡å†…å®¹æ˜¯å¦ä¸€è‡´
        if memory_index.ntotal > 0 and disk_index.ntotal > 0:
            memory_vectors = memory_index.reconstruct_n(0, min(3, memory_index.ntotal))
            disk_vectors = disk_index.reconstruct_n(0, min(3, disk_index.ntotal))
            
            vectors_match = np.array_equal(memory_vectors, disk_vectors)
            print(f"   - å‘é‡å†…å®¹ä¸€è‡´: {'âœ…' if vectors_match else 'âŒ'}")


if __name__ == "__main__":
    try:
        analyze_faiss_files()
        compare_memory_vs_disk()
        print("\nâœ… åˆ†æå®Œæˆ")
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc() 